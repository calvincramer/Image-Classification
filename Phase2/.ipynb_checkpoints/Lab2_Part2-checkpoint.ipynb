{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtQH3witU_4n"
   },
   "source": [
    "# Lab 2 Part 2: Transfer Learning with Pytorch\n",
    "The goal for the second part of the lab is to familiarize you with another technique to train deep neural networks called transfer learning. Typically in neural networks you will have a lot of layers and not enough training data. This is especially true for this class, where the amount of data and types of differently annotated data we can get are very limited. Typically, neural networks are fed with millions of images in order to generalize well. The good thing is, if someone hands us a pretrained network we can still \"use\" all that data they trained with by retraining the parameters for our purposes. In this case, we will continue with our car classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cSV4rLiLV4MG"
   },
   "source": [
    "## Import the necessary libraries\n",
    "We will import Pytorch and various modules within it, as well as numpy, matplotlib, and some Python system libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Linear\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7-RIeS_U52p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU AVAILABLE:  True\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.init() #DELETE ME\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "print(\"GPU AVAILABLE: \", USE_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNWpPPj3WcSR"
   },
   "source": [
    "In this step of the lab, you will construct a data loader to actually import the images from our dataset. Luckily, Pytorch has built in support for dataset objects. In this section, we have provided skeleton code for a dataset object. Please refer to the [Pytorch documentation](https://pytorch.org/docs/0.4.0/), as well as this [tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) to figure out how to properly load data for a neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IHWTPky8U52t"
   },
   "outputs": [],
   "source": [
    "# Car Dataset Object\n",
    "# Child of Dataset class\n",
    "class CarDataSet(Dataset):\n",
    "    # CarDataset constructor\n",
    "    # Inputs:\n",
    "    # path - string containing path to a directory of car dataset images\n",
    "    # transform - a transform to be done on the image; defaults to none if \n",
    "    #     no transforms are needed\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path      = path\n",
    "        self.transform = transform\n",
    "        self.imageList = os.listdir(self.path)\n",
    "    \n",
    "    # Retrieves image at specified index and returns the image along with a label\n",
    "    # Inputs:\n",
    "    # idx - specified image index\n",
    "    # Outputs:\n",
    "    # sample - structures containing images and their corresponding labels\n",
    "    def __getitem__(self, idx):\n",
    "        ### TODO ###\n",
    "        #READ IMAGE AND LABEL\n",
    "        imageName = self.imageList[idx]\n",
    "        image = os.path.join(self.path, imageName)\n",
    "        label = 0\n",
    "        if imageName[0:3] == \"pos\" or imageName[0:4] == \"test\":\n",
    "            label = 1\n",
    "            \n",
    "        image = Image.open(image).convert(\"RGB\")\n",
    "        if self.transform != None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = (image, label)\n",
    "        return sample\n",
    "    \n",
    "    # Return the number of images in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.imageList)\n",
    "    \n",
    "    # Plot and visualize an image and its corresponding label\n",
    "    def visualize(self, idx):\n",
    "        img_name = self.imageList[idx]\n",
    "        img_loc = os.path.join(self.path, img_name)\n",
    "        image = io.imread(img_loc)\n",
    "        _, label = self.__getitem__(idx)\n",
    "        plt.imshow(image)\n",
    "        # PRINT LABEL ON IMAGE\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rVAKDwMYsQc"
   },
   "source": [
    "## Import the dataset into a data loader object\n",
    "After constructing the dataset, we want to get it into a dataloader object as well as apply any necessary transformations on the image. Again, please refer to the [Pytorch documentation](https://pytorch.org/docs/0.4.0/), as well as the previously mentioned [data processing tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html). You must apply two transforms at minimum, one to convert the images to torch tensors, and the other to normalize the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number images in training set:  1050\n"
     ]
    }
   ],
   "source": [
    "### TODO ###\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset_train = CarDataSet(\"/LAB2/Phase2/TrainImages/\", trans)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=16, shuffle=False) \n",
    "print(\"Number images in training set: \", len(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Q7Kd2VfU52w"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACoCAYAAADw6BWzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQOALusPhcAwI/j/728PdDES2LAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train.visualize(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqJdnKUBZ6yT"
   },
   "source": [
    "## Model Definition\n",
    "Now that the data has been loaded into a data loader object, we can define our model. We will be using the resnet18 architecture ([original paper](https://arxiv.org/pdf/1512.03385.pdf)) with pretrained weights on the [ImageNet dataset](http://www.image-net.org/). In order to do transfer learning, we need to redefine the last fully connected layer in the pretrained model, and then retrain the whole network with our new final layer and new images. In this section, you need to redefine the new layer, choose an optimizer, and choose a loss function for the model. After doing so, you will create a training function to actually train model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ghDKJ3TMZzEr"
   },
   "outputs": [],
   "source": [
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "#TAKE LAST FULLY CONNECTED LAYER AND MAKE IT ONLY HAVE TWO OUTPUT NODES\n",
    "#print(model_resnet18.parameters)\n",
    "model_resnet18.fc = Linear(in_features=512, out_features=2, bias=True)\n",
    "if USE_GPU:\n",
    "    model_resnet18 = model_resnet18.cuda()\n",
    "    \n",
    "# Loss function and optimizer\n",
    "loss_resnet18 = CrossEntropyLoss()\n",
    "optimizer_resnet18 = SGD(model_resnet18.parameters(), lr=0.0001, momentum=0.1, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLNYIPJObEXX"
   },
   "source": [
    "## Creating the training loop\n",
    "The last step of the lab is to create the training loop. There are 5 parameters in our training function, all of them are neural network hyperparameters. We have the model architecture, loss function, optimizer, and learning rate. The fifth hyperparameter we work with here is the number of epochs. This is a measure of the number of times you want the model to 'see' the training set. The default value is 25 times, but the model may need more or less passes in order to generalize well. Your goal for this section is to write the training loop to train this model. Recall from lecture that there are 4 main steps to training a model. \n",
    "1. Inference/Current Prediction\n",
    "2. Compute the loss for the current prediction\n",
    "3. Compute the gradients of the loss with respect to the model parameters using backpropagation\n",
    "4. Update model weights and repeat\n",
    "\n",
    "Again, refer to the [Pytorch documentation](https://pytorch.org/docs/0.4.0/) as well as the following [tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "noLSL0wBU52z"
   },
   "outputs": [],
   "source": [
    "def train_model(model, loss_func, optimizer, lr_scheduler, num_epochs=25):\n",
    "    stamp = time.time()\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 99999999999999999999\n",
    "    \n",
    "    # Loop over the number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, sample in enumerate(dataloader_train, 0):\n",
    "            x, y_real = sample  # get the inputs\n",
    "            if USE_GPU:\n",
    "                x = x.cuda()\n",
    "                y_real = y_real.cuda()\n",
    "\n",
    "            optimizer.zero_grad() # zero the parameter gradients\n",
    "            y_predict = model(x)  # Forward propogation\n",
    "            loss = loss_func(y_predict, y_real)  # Calculate loss between y_predict and y_real\n",
    "            loss.backward()   # Back propagation (just calculates the derivatives)\n",
    "            optimizer.step()  # Use derivatives to step in correct direction\n",
    "\n",
    "            # print statistics\n",
    "            ### TODO: Add running loss ###\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        ### TODO: Compute loss for whole epoch\n",
    "        epoch_loss = running_loss * 1.0 / len(dataset_train)\n",
    "        print('Loss: {:.4f}'.format(epoch_loss))\n",
    "\n",
    "        ### TODO: Update best weights if they have the lowest loss ###\n",
    "        if running_loss < best_loss:\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            best_loss = running_loss\n",
    "        \n",
    "    elapsed = time.time() - stamp\n",
    "    print(\"Training complete in {:.0f} min {:.0f} sec\".format(elapsed // 60, elapsed % 60))\n",
    "    \n",
    "    model.load_state_dict(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpjXFG15dsMw"
   },
   "source": [
    "## Run our Training Function for our defined hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fxC-45vU526",
    "outputId": "b320ac00-8413-4776-944d-09090ac0c9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "--------------------\n",
      "Loss: 0.0477\n",
      "Epoch 1/24\n",
      "--------------------\n",
      "Loss: 0.0362\n",
      "Epoch 2/24\n",
      "--------------------\n",
      "Loss: 0.0315\n",
      "Epoch 3/24\n",
      "--------------------\n",
      "Loss: 0.0281\n",
      "Epoch 4/24\n",
      "--------------------\n",
      "Loss: 0.0254\n",
      "Epoch 5/24\n",
      "--------------------\n",
      "Loss: 0.0232\n",
      "Epoch 6/24\n",
      "--------------------\n",
      "Loss: 0.0213\n",
      "Epoch 7/24\n",
      "--------------------\n",
      "Loss: 0.0197\n",
      "Epoch 8/24\n",
      "--------------------\n",
      "Loss: 0.0183\n",
      "Epoch 9/24\n",
      "--------------------\n",
      "Loss: 0.0171\n",
      "Epoch 10/24\n",
      "--------------------\n",
      "Loss: 0.0161\n",
      "Epoch 11/24\n",
      "--------------------\n",
      "Loss: 0.0151\n",
      "Epoch 12/24\n",
      "--------------------\n",
      "Loss: 0.0143\n",
      "Epoch 13/24\n",
      "--------------------\n",
      "Loss: 0.0135\n",
      "Epoch 14/24\n",
      "--------------------\n",
      "Loss: 0.0129\n",
      "Epoch 15/24\n",
      "--------------------\n",
      "Loss: 0.0122\n",
      "Epoch 16/24\n",
      "--------------------\n",
      "Loss: 0.0117\n",
      "Epoch 17/24\n",
      "--------------------\n",
      "Loss: 0.0112\n",
      "Epoch 18/24\n",
      "--------------------\n",
      "Loss: 0.0107\n",
      "Epoch 19/24\n",
      "--------------------\n",
      "Loss: 0.0103\n",
      "Epoch 20/24\n",
      "--------------------\n",
      "Loss: 0.0099\n",
      "Epoch 21/24\n",
      "--------------------\n",
      "Loss: 0.0095\n",
      "Epoch 22/24\n",
      "--------------------\n",
      "Loss: 0.0092\n",
      "Epoch 23/24\n",
      "--------------------\n",
      "Loss: 0.0088\n",
      "Epoch 24/24\n",
      "--------------------\n",
      "Loss: 0.0085\n",
      "Training complete in 1 min 48 sec\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_resnet18, loss_resnet18, optimizer_resnet18, lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with a Fixed Feature Extractor\n",
    "There is an even simpler way to train the pretrained Resnet18 architecture. We can do this by freezing the weights in the convolutional layer and only training the final layer that we redefined earlier. The code should be very similar to what was written above. Your goal is to figure out how to load the pretrained model and freeze all the weights in the network besides the final layer that you redefine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frozen_conv = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model_frozen_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "model_frozen_conv.fc.requires_grad = True\n",
    "\n",
    "model_frozen_conv.fc = Linear(in_features=512, out_features=2, bias=True)\n",
    "\n",
    "\n",
    "if USE_GPU:\n",
    "    model_frozen_conv = model_frozen_conv.cuda()\n",
    "    \n",
    "# Loss function and optimizer\n",
    "frozen_loss_resnet18 = CrossEntropyLoss()\n",
    "frozen_optimizer_resnet18 = SGD(model_frozen_conv.parameters(), lr=0.0001, momentum=0.1, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "--------------------\n",
      "Loss: 0.0465\n",
      "Epoch 1/24\n",
      "--------------------\n",
      "Loss: 0.0421\n",
      "Epoch 2/24\n",
      "--------------------\n",
      "Loss: 0.0398\n",
      "Epoch 3/24\n",
      "--------------------\n",
      "Loss: 0.0378\n",
      "Epoch 4/24\n",
      "--------------------\n",
      "Loss: 0.0361\n",
      "Epoch 5/24\n",
      "--------------------\n",
      "Loss: 0.0345\n",
      "Epoch 6/24\n",
      "--------------------\n",
      "Loss: 0.0331\n",
      "Epoch 7/24\n",
      "--------------------\n",
      "Loss: 0.0318\n",
      "Epoch 8/24\n",
      "--------------------\n",
      "Loss: 0.0306\n",
      "Epoch 9/24\n",
      "--------------------\n",
      "Loss: 0.0295\n",
      "Epoch 10/24\n",
      "--------------------\n",
      "Loss: 0.0284\n",
      "Epoch 11/24\n",
      "--------------------\n",
      "Loss: 0.0275\n",
      "Epoch 12/24\n",
      "--------------------\n",
      "Loss: 0.0266\n",
      "Epoch 13/24\n",
      "--------------------\n",
      "Loss: 0.0258\n",
      "Epoch 14/24\n",
      "--------------------\n",
      "Loss: 0.0251\n",
      "Epoch 15/24\n",
      "--------------------\n",
      "Loss: 0.0244\n",
      "Epoch 16/24\n",
      "--------------------\n",
      "Loss: 0.0238\n",
      "Epoch 17/24\n",
      "--------------------\n",
      "Loss: 0.0232\n",
      "Epoch 18/24\n",
      "--------------------\n",
      "Loss: 0.0226\n",
      "Epoch 19/24\n",
      "--------------------\n",
      "Loss: 0.0221\n",
      "Epoch 20/24\n",
      "--------------------\n",
      "Loss: 0.0216\n",
      "Epoch 21/24\n",
      "--------------------\n",
      "Loss: 0.0211\n",
      "Epoch 22/24\n",
      "--------------------\n",
      "Loss: 0.0207\n",
      "Epoch 23/24\n",
      "--------------------\n",
      "Loss: 0.0203\n",
      "Epoch 24/24\n",
      "--------------------\n",
      "Loss: 0.0199\n",
      "Training complete in 1 min 17 sec\n"
     ]
    }
   ],
   "source": [
    "model_frozen_conv = train_model(model_frozen_conv, frozen_loss_resnet18, frozen_optimizer_resnet18, lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "#def accuracy method\n",
    "def calc_accuracy(model, data_loader, len_dataset):\n",
    "    num_correct_predictions = 0\n",
    "\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        x, y_real = data  # get the inputs\n",
    "        if USE_GPU:\n",
    "            x = x.cuda()\n",
    "            y_real = y_real.cuda()\n",
    "\n",
    "        y_predict = model(x)  # Forward propogation\n",
    "        _, predicted_nums = y_predict.data.max(1)  # Get indicies of maximum elements\n",
    "        diff = predicted_nums.sub(y_real)          # Take difference between prediction and real\n",
    "        if USE_GPU:\n",
    "            diff = diff.cpu()\n",
    "        diff = diff.numpy()\n",
    "        num_right = len(diff) - np.count_nonzero(diff) # A non zero value is an incorrect prediction\n",
    "        num_correct_predictions = num_correct_predictions + num_right\n",
    " \n",
    "    acc = num_correct_predictions * 1.0 / len_dataset\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Training Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of wholly trained model:  0.9847619047619047\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy of wholly trained model: \", calc_accuracy(model_ft, dataloader_train, len(dataset_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of frozen model:  0.9238095238095239\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy of frozen model: \", calc_accuracy(model_frozen_conv, dataloader_train, len(dataset_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number images in test set:  1050\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE TESTING ACCURACIES\n",
    "# ALL PHOTOS IN THE TESTING DATASET ARE CARS!\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset_test = CarDataSet(\"/LAB2/Phase2/TestImages/\", trans)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=16, shuffle=False) \n",
    "print(\"Number images in test set: \", len(dataset_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Testing Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of wholly trained model:  0.611764705882353\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy of wholly trained model: \", calc_accuracy(model_ft, dataloader_test, len(dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of frozen model:  0.5294117647058824\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy of frozen model: \", calc_accuracy(model_frozen_conv, dataloader_test, len(dataset_test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab2_Part2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
