{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torchvision import transforms\n",
    "import multiprocessing\n",
    "import os\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTDataSet(Dataset):\n",
    "    '''\n",
    "    path2file - string - path of the MNIST dataset, must be .pt file\n",
    "    transform - torchvision.transforms - synonymous with handler, what does this do\n",
    "    '''\n",
    "    def __init__(self, path2file, transform_handler=None):\n",
    "        self.data_path = path2file\n",
    "        self.transform_handler = transform_handler\n",
    "        self.data_model = torch.load(self.data_path)\n",
    "        # Extract and save the information in the class\n",
    "        \n",
    "    \"\"\"\n",
    "    index - index of image in dataset, no bounds checking done\n",
    "    Returns tuple of (image, number), where image is a 2D tensor, and number is a 0-dim tensor\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        tens = self.data_model[0][index]\n",
    "        tens = tens.float() # To float tensor\n",
    "        tens = tens / 255.0 # Normalize\n",
    "        if (self.transform_handler != None):\n",
    "            \"\"\"\n",
    "            tens = self.data_model[0][index]\n",
    "            tens = tens.float()\n",
    "            print(\"size of tens: \", tens.size())\n",
    "            tens = tens.unsqueeze(-1) # Make tensor 3D, since ToPILImage complains\n",
    "            print(\"size unsqueezed: \", tens.size())\n",
    "            \n",
    "            import IPython;IPython.embed()\n",
    "            \n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                # normalize\n",
    "                # transforms.Normalize(),\n",
    "                #self.transform_handler,\n",
    "                transforms.Resize(10),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            b = transform(tens)\n",
    "            b = tens.squeeze(-1)\n",
    "            return (b, self.data_model[1][index])\n",
    "            \"\"\"\n",
    "            tens = self.transform_handler(tens)\n",
    "        else:\n",
    "            return (tens, self.data_model[1][index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/LAB2/Phase1/data/processed/training.pt <class 'str'>\n",
      "model type:  <class 'tuple'>\n",
      "num pics:  60000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAABLCAYAAAA4TnrqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA+1JREFUeJzt2k2ITX0cB/DP8XYRaQhbpdhYiCxk\naJIkK2JD1ooVyYZSKEkpM7FR42Upb8kOZaPIRiwkKyKU8lLkJdxnwXGfuRozv3HPzPU8v8/23HPO\nv+/93nP/539OUa/XpcEZNdID+JtkWAEZVkCGFZBhBWRYARlWQIYVkGEFjIl8uCiK/+x0v16vFwN9\nJhTWj4MObTRtrCgGzAn5MwzJsAIyrIAMKyDDCsiwAjKsgPA8q0rfvn0Dnz59+mXb6dOnwfv378H9\n+/fBkSNHwK5du8DRo0fBhAkTwOHDh8GWLVv+eHzZrIBhbdbbt2/B169fwd27d8GVK1fAmzdvwPHj\nxwc81qxZs8COHTtAb28vmDJlCli6dClYvnx5K4aObFZIEbnXK4qiPpR7w6dPn4L58+eD169fh49R\nGjXq+/d79epVNK5NpRkzZoBJkyaB6dOnD3jMoigGdSOdzQoYlmvWtGnTwMyZMzG4Zq1cubLPvhcu\nXAC1Wg10dXW1epgDymYFDEuzyuvKqVOnwLlz58DixYvBunXr+ny+s7PTpUuXwLhx48CLFy9Ad3d3\n5ePtTzYrYFj+DZuVM/SyNeXs+9ChQ+D69euWLVv2x+cZrPw3rMCIhFWr1dRqNUVRKIpCR0eHjo6O\nn9t7enrU6/W2W+/PZgWMyDWr2efPn8HGjRvBxYsXf943zps3r+Xna5bXrAq0RbNKr169ArNnzzZ1\n6lSwZs0asGTJErB27dpyLC0772Cb1VZhlW7fvm3VqlVoLOuUTpw4gcZEtrxh/hP5M6xAWzYLnj9/\nDrZv3w7Onj3bZ/vu3bvBzp07weTJk4d8rmxWBdq2WaWPHz+CW7dugRUrVqDxgsr69evBmTNnhnyO\nbFYF2r5ZzcrFvy9fvoAxY76vMt27dw/MnTs3fMxsVgXa6iHrvz179gyN5eSbN2+i0ajSokWLwJw5\ncyofUzYroK2a9fLlS3Ds2DEnT55E4zFas9GjR6PxsLWVtz/9yWYFjGiz3r17By5fvgz27dsHHj58\n2O8+5eP4gwcPgoULF1Y5xD6yWQHD2qzydaEnT56ATZs2gTt37vS7T/mwde/evWj8+w3HNapZNiug\n0mZ9+PABbNu2Ddy4cQM8ePDgt/utXr3anj170HiZZOzYsVUNc9CyWQEtbdajR4/AgQMHwLVr18Dj\nx49/u9/EiRPB/v37wdatW38+gG0n2ayAljbr/PnzaLyy2GzBggVgw4YN30/+Y8Vg8+bNYPz48a0c\nTstlswL+uvWsKuR6VgUyrIAMKyDDCsiwAsLzrJG4228XoanD/13+DAMyrIAMKyDDCsiwAjKsgAwr\nIMMKyLAC/gFNCj2eXXrugQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAABLCAYAAAA4TnrqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABA5JREFUeJzt2z1oFFsYxvHfxEs0fiBGUIgEFUWw\nikVKRcsFKzEJgrEQsQh+IagBxUZiIRYhQRLUTgI2Ib1gkwSiVVKIdmriR6OCIlEUxb3FveOwq5A9\nyc4m13v+zcDu2fMeHp55z3vemU2KxaJIZdQt9gL+S0SxAohiBRDFCiCKFUAUK4AoVgBRrACiWAH8\nFTI4SZI/ttwvFovJXGOCxPp30vmtZgmTJHPqhHgbBhHFCiCKFUAUK4AoVgDBu2GtefnyJejr6wO9\nvb3g7Nmz4MyZM6C5uTn3tURnBZCE1E1JkhRrVWe9fv0atLS0gA8fPvx23Lp168Dbt2/nHStJkoqK\n0uisAJZkzpqZmbFv3z7w/v17ZFX22rVrwfLly8GbN2/As2fPwObNm8GyZcuqvq7orACWRM769u0b\n/nEUFAoF09PTyM6iqbP27t0Lrl69Cnbv3l0y7tatW+DYsWMVx485KweWRM46f/48uHHjxpxjR0dH\nwadPn8CBAwfAyMgImJqaymOJiM4KYlGdlVbnQ0NDKO2VpY45ePAg6OzsRFap79y5E3R3d4Ph4eFf\n5qg20VkBLMpuOFd1fvjwYbdv3wZPnjwBk5OT4NChQ2DlypUlv0nrqlWrVoHHjx+jsjNj3A1zoKY5\n6927d+DatWvIqvONGzeCrVu3gq6uLvX19WDXrl0l17n4/PkzuH79Oujv76/G0hGdFURNnPX9+3dw\n7tw5ZLtfes67d+8e2L59O7KKfiE8f/58wXOUE50VQE2c9eLFC2SOSnn48CHYsWNHyecNDQ21WFYw\nNRHrxIkTyArGtOAsF2kh/PjxA9TV1ZXEqibxNgwgV2elh9qxsTFkbZb29vaqx0odlcZobW2tfoyq\nz/gHk6uzvnz5Ar5+/QqamprA/v37Fzx3Wo6UF51tbW3g4sWLC45RTnRWADU97qxYsQKsXr163nOk\njhocHAQXLlwAW7ZsAZcuXYKfx6VqEp0VQE2ddeTIkXn/Nm3rpIfwgYEBcPToUfjZ0smT6KwAcm3+\nTUxMgD179iDLK0+fPq14jrt374JTp04ha+ucPn0a2YsiCyE2/3Ig15yVVtPp9dWrV+DKlSvIHoSu\nWbMGWSv45s2bxsfH4efD1m3btiFrK6fOqiXRWQHkmrMePHiALGeVs2nTJtDY2AgePXr0y5hCoVBy\nPXnyZMXxKyXmrBzI1VkfP34EHR0d4P79+yXfl7/0kbJhwwZdXV3g8uXLFcebL9FZOVCTh6yzs7Pg\nzp07yHaycmf19PSA48ePW79+fXCc+RKdlQNL4mW2xSY6KweiWAFEsQKIYgUQxQogihVAFCuA4H5W\npX++/hMJKkr/78TbMIAoVgBRrACiWAFEsQKIYgUQxQogihVAFCuAvwGWgFybA/enYAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAABLCAYAAAA4TnrqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAAwxJREFUeJztmzEvLFEYhp9zIyLoRLVRSCRoREWl\nEipR2E4jUek0Oj9AT6dT6kUhsaEShYpYoZAtaDZBgQThKNzJZETWvDdnZo37Pc1mds+eb/LkPTvf\nmd113nuMdPxp9gkUCZMlYLIETJaAyRIwWQImS8BkCZgsgRZlsHPu17b73nv33RhJ1t9J/+1sfjDO\nfesJsGUoYbIETJaAyRIwWQImS8BkCfwaWdVqlWq1SqlUolQqUa/XqdfrQWv8Gll5IHfwjbi4uADg\n9vYWgJGRkZDTN+Tw8BCA8fHxzGpYsgSCJmt3dxeAs7MzIJ9kRXvVKNXn5+eZ1bJkCQRN1urqKgCT\nk5Mhp23I/f09ACsrKwAsLi4C0N3dHbyWJUsgaLJeX19DTpeKhYWFxPHg4GBmtSxZAkGSdX19DcDV\n1VWI6SRubm4SxxMTE5nVsmQJBEnWzs4OAI+PjyGmS8XDwwMAx8fHiee7uroyq2nJEgiSrJOTk8Tx\n8PBwiGkbsry8DMSfl0NDQwC0trZmVtOSJRC0z4oYHR0NNtfT0xMAR0dHAKyvrwOwubmZGBftHtra\n2oLV/kwmsu7u7hq+Hi2dt7c3APb39wG4vLwE4Pn5mbW1NSBudDs6OoB4KxVJeXl5AbJtRiNsGQoE\nSVZ7ezsQfw0+PT0NQH9//5fjDw4OgPj2SkvLx2l0dnYCH8t4aWkJgLGxMSC+aEQJ6+npAeIWIouN\n82csWQJO+aGHc843Gr+xsQHA3t5eqvlmZ2cB6OvrA6C3t/fb92xvbwMwNTUFwMDAAACnp6epan6F\ncy7Vr2gsWQJBr4Zzc3OJxyzY2tpKHM/Pz2dW6zOWLIFM+qw8mZmZya2WJUvAZAmYLIHCyvLe472n\nVqtRq9VyqVlYWc2gsFfDaB8a3bnIA0uWQOFlVSoVKpVKLrUKLytPCvuZ1Yy/xViyBAonq1wuUy6X\ncc6l/oNSKAonq5kEvVNaVOxOaQaYLAGTJWCyBEyWgNzB593b/CSk1uF/x5ahgMkSMFkCJkvAZAmY\nLAGTJWCyBEyWwDuQhskHkxW+jQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAABLCAYAAAA4TnrqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAArpJREFUeJzt2zFLI0EAxfH/qGghYiEWYivGIlhY\n2VhYBbQQBHvTWQfBUkubfAJt7SSNnaAIgo29oNiJnUhAECv3iruwxOiZp9nd8e79yt3gDs+3M5NN\nEpIkwbrTV/QAfhKHJXBYAoclcFgChyVwWAKHJXBYggHlxSGEf3a7nyRJ+Ow1Ulh//ujXRhOxED7N\nCfBtKHFYAoclcFgChyVwWAKHJZD3WbHY29sDYGNjA4DX11cArq+vAZienu75Nd0swY9r1snJCQC1\nWg2Avr72/3e3u/GvcLMEP65ZNzc3ALy8vOR+bTdLEJSnCCGEpKinDldXVwAsLi4C8Pj4CMDc3BwA\nx8fHAAwPDwMwMND9TRNC6OoRjZsliH7Our29BWBpaQlIG9Wyu7sLwOjoaOZjcbME0Tdrf38fgLu7\nu7bjq6urQDqH5cHNEkS7Gj4/PwMwMjICpDv1sbExAM7OzgCYmZn59rW8GmYgyjmr2WyysrLy7rmd\nnR2gN41SuVmCKJt1fn7OxcVF27G1tTUA1tfXCxjRb1FN8JeXlwBUKhWenp4AWF5eBuDg4ABI3870\nkif4DERxGzabTQDm5+c7zk1NTQHZNErlZgmiaFa9Xgc6HxEDbG1t5T2cD7lZgkKbdX9/D8Dh4WHH\nuWq1CsD4+HiuY/obN0tQ6D5rYmICgIeHh7bjlUqFRqMBwODgYM+u9xHvszJQaLP6+/uBzlXw9PSU\nhYWFnl3nM25WBgpZDTc3N4H0yxxvzc7O5jmcrrlZglyb9XZf1ZqrhoaGANje3gbieB/4HjdLkOtq\n2PqiWblcBtI5q1QqAelH9HnzapgBhyVwWIJcV8PJyUkgfa5+dHSU5+W/zc0SRPXpTlG8GmbAYQkc\nlsBhCRyWQN5nZflzj9hJW4f/nW9DgcMSOCyBwxI4LIHDEjgsgcMSOCzBL5OVxguoStF2AAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAABLCAYAAAA4TnrqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA7VJREFUeJztm00obGEYx3+v71jYKCx8FEqaDUmS\nnYVkgwUWSBbK0ko2NiwsEWUlG4UsLJUkRchKllNSKJNYiBqFuQv3nOm4bnMe15l5773PbzP1nvec\n8/Sf//u8z3nOjInFYij+SEt1AH8TKpYAFUuAiiVAxRKgYglQsQSoWAJULAEZksnGmH+23I/FYibR\nHJFYPy/6tWgsxpiEOgG6DEWoWAJULAEqlgAVS4CKJUDFEqBiCVCxBKhYAlQsAeJnwyC5uLgAYHl5\nma2tLQBOTk48c1ZWVgAoKSkBYHt7G4DBwUEAysvLA4tPnSXACmcdHBwA0N3dDUAkEnG7G11dXQBc\nXl4C0NfX5znXmXd7ewvAwsJCYHGqswSkxFlvb29APEe1t7cD8Pj4CEBHRwdTU1MAVFVVAfD6+grA\n0NAQAKurq55rNjU1BRs06iwRRtL5NMbEvqNTurOzA0Bra6tnvKenB4ClpSWys7M9x/b29gBoaWnx\njJeVlQFwdnYGQG5urjgeY4yvtrI6S0BSnTU3NwfA6Oiocz0AJiYmABgbGwP4xVUAtbW1QNxBDkdH\nRwDU19d/OS51VgAkZTdcXFwE4o5ynNPb2wvA+Pg4AJmZme45Ly8vAJyengIQDoeBeF3luPRPHCVF\nnSUg0JwVjUYBqKioAN4rc4CBgQHgfdf7jPv7e3dn3N3d9RwbHh4GYGZmBoCsrCzf8fwOvzkrULGe\nnp4AyM/P94zf3d0BkJHxngU2NjYAWFtbA+Dw8JCHhwfnnp7P4+NjAOrq6nzHkQhN8AGQlGVYWVkJ\nwM3NDRBP0r97bV5aWurOcR6gi4qKALi6uvJ9f7+oswIg0NIhJycHgP39fQAaGxuBeDulpqYGgP7+\nfiCe+PPy8twxx1kjIyNBhuoLdZaApBSlTqvXyVmJCIfDbG5uApCW9v59VldXBxKbBHWWACvayh+J\nRqOuo5wds62tLZUhAeosESlp/vkhPT3duSeAW9F/pbmXCK2zAsBKsT42+GzBSrFsxUqxzs/PUx3C\np1gplq1YWWc1NDS4L2KdessG7InkL8BKsYqLiwmFQoRCIYwxGGOIRCJuWzpVWCmWrVhbwX98xd/Z\n2QnA/Pw8AIWFhd92L63gA8DK3RCgubkZiP/AbX19HYCCggIAZmdnge95FeYXdZYAa3OWw/PzMwDT\n09MATE5OAnB9fQ18T+7SnBUA1jsrGaizAkC8G/r98/W/iGgZ/u/oMhSgYglQsQSoWAJULAEqlgAV\nS4CKJUDFEvADqtJAoK8Xmr4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Displays a tensor that represents a monocrome image\n",
    "'''\n",
    "'''\n",
    "def show_mono_img(tens):\n",
    "    if (type(tens) != torch.Tensor):\n",
    "        raise Exception(\"Input argument should be torch.Tensor type\")\n",
    "    img = tens.numpy()\n",
    "    \n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "    plt.rcParams[\"axes.linewidth\"] = 1\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    \n",
    "    plt.imshow(img, cmap='Greys', interpolation='none')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# DEBUGGING, COMMENT OUT TO TEST\n",
    "# Get input data set file\n",
    "inp_file = os.getcwd()\n",
    "inp_file = inp_file + \"/data/processed/training.pt\"\n",
    "print(inp_file, type(inp_file))\n",
    "\n",
    "# Instantiate dataset object\n",
    "\n",
    "ds = MNISTDataSet(inp_file, None)  # Without transformation\n",
    "#ds = MNISTDataSet(inp_file, transforms.Resize(5)) # With a transformation\n",
    "\n",
    "print(\"model type: \", type(ds.data_model))\n",
    "#for i in range(len(ds.data_model)):\n",
    "#    print(\"Model tuple index \", i, \" is of type: \", type(ds.data_model[i]), \", example: \", ds.data_model[i][0])\n",
    "print(\"num pics: \", len(ds))\n",
    "#print(ds.data_model)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    img_tensor, class_tensor = ds[i]\n",
    "    #print(\"type of image: \", type(ds[i]))\n",
    "    #print(\"dim of image: \", ds[i].size())        \n",
    "    show_mono_img(img_tensor)\n",
    "    print(class_tensor.item())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to convert the juypter notebook to a python file\n",
    "!jupyter nbconvert --to script dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
