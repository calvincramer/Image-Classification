{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook model.ipynb to script\n",
      "[NbConvertApp] Writing 4445 bytes to model.py\n"
     ]
    }
   ],
   "source": [
    "#import IPython;IPython.embed()\n",
    "from model import mnist_2Layer # my model.py\n",
    "from model import mnist_5Layer\n",
    "from model import mnist_modified\n",
    "from dataset import MNISTDataSet # my dataset.py\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Compose, Normalize, Resize, ToTensor\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD:  /LAB2/Phase1\n",
      "Path to dataset:  /LAB2/Phase1/data/processed/training.pt\n",
      "Path to model checkpoints save file:  /LAB2/Phase1/modelmodified_checkpoints.pt\n",
      "Path to model save file:  /LAB2/Phase1/modelmodified.pt\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_MODEL = \"modelmodified\"   # NAME OF FILE TO SAVE THE MODEL IN\n",
    "cwd = os.getcwd()\n",
    "print(\"CWD: \", cwd)\n",
    "mnist_dataset_path = cwd + \"/data/processed/training.pt\"\n",
    "print(\"Path to dataset: \", mnist_dataset_path)\n",
    "model_checkpoint_save_path = cwd + \"/\" + OUTPUT_MODEL + \"_checkpoints.pt\"\n",
    "print(\"Path to model checkpoints save file: \", model_checkpoint_save_path)\n",
    "model_save_path = cwd + \"/\" + OUTPUT_MODEL + \".pt\"\n",
    "print(\"Path to model save file: \", model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU AVAILABLE:  True\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.init()\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "print(\"GPU AVAILABLE: \", USE_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "model = mnist_modified()  # MAKE SURE THE INSTANTIATE MODEL IS THE SAME AS THE FILE WHERE YOU SAVE THE WEIGHTS IN\n",
    "if USE_GPU:\n",
    "    model = model.cuda()  # Run on GPU\n",
    "loss_f = CrossEntropyLoss() # Need any parameers?\n",
    "optimizer = SGD(model.parameters(), lr=0.1, momentum=0.1, nesterov=True)  # Can also specify momentum here\n",
    "train_dataset = MNISTDataSet(mnist_dataset_path)\n",
    "data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)  \n",
    "# If shuffle is True, will shuffle every epoch, but dataset is already shuffled\n",
    "\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Starting epoch  0\n",
      "[  100] loss: 2.221\n",
      "[  200] loss: 0.963\n"
     ]
    }
   ],
   "source": [
    "epochs= 1\n",
    "running_loss = 0.0\n",
    "window = 100  # A window is 100 batches\n",
    "saved_weights = []\n",
    "saved_losses = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch_num in range(epochs):\n",
    "    print(\"Starting epoch \", epoch_num)\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        x, y_real = data  # get the inputs\n",
    "        if USE_GPU:\n",
    "            x = x.cuda()\n",
    "            y_real = y_real.cuda()\n",
    "        # x is a [8, 28, 28] dim Tensor, 8 for the batch, each slice is an image\n",
    "        # y_read is a [8] dim Tensor, with a number for the actual digit each picture is\n",
    "                \n",
    "        # Make x into 4d Tensor, to adhere to [8,1,28,28], since we always have 1 channel\n",
    "        x = x.unsqueeze(1)\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        y_predict = model(x)  # Forward propogation\n",
    "        loss = loss_f(y_predict, y_real)  # Calculate loss between y_predict and y_real\n",
    "        loss.backward()   # Back propagation (just calculates the derivatives)\n",
    "        optimizer.step()  # Use derivatives to step in correct direction\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % window == window-1:    # print every 2000 mini-batches\n",
    "            loss_num = running_loss / window\n",
    "            print('[%5d] loss: %.3f' %(i + 1, loss_num))\n",
    "            \n",
    "            #TODO save your weight for very window\n",
    "            torch.save({\n",
    "                'epoch': epoch_num,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss_f,\n",
    "            }, model_checkpoint_save_path)\n",
    "            \n",
    "            \n",
    "            saved_weights.append(model.parameters())\n",
    "            saved_losses.append([(i+1) + (epoch_num*len(train_dataset)/BATCH_SIZE), loss_num])\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            #print(\"loss     : \", loss)\n",
    "            #print(\"Y predict: \", y_predict)\n",
    "            #print(\"Y real   : \", y_real, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished Training')\n",
    "# Save whole model\n",
    "torch.save(model, model_save_path)\n",
    "print(\"Saved model to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss over the training process\n",
    "saved_losses = np.array(saved_losses)\n",
    "plt.plot(saved_losses[:,0], saved_losses[:,1], label=\"Loss over epoch 1\")\n",
    "plt.xlabel(\"Image number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
